{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC Score Optimization: Ensemble and Regularization\n",
    "#Author: Sudesh V Khillare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cost_of_ad</th>\n",
       "      <th>device_type</th>\n",
       "      <th>gender</th>\n",
       "      <th>in_initial_launch_location</th>\n",
       "      <th>income</th>\n",
       "      <th>n_drivers</th>\n",
       "      <th>n_vehicles</th>\n",
       "      <th>prior_ins_tenure</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>62717</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>desktop</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>64328</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>laptop</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>83439</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>Android</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>30110</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>desktop</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>76565</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  cost_of_ad device_type gender  in_initial_launch_location  income  \\\n",
       "0   56    0.005737      iPhone      M                           0   62717   \n",
       "1   50    0.004733     desktop      F                           0   64328   \n",
       "2   54    0.004129      laptop      M                           0   83439   \n",
       "3   16    0.005117     Android      F                           0   30110   \n",
       "4   37    0.003635     desktop      M                           0   76565   \n",
       "\n",
       "   n_drivers  n_vehicles  prior_ins_tenure  outcome  \n",
       "0          2           1                 4        0  \n",
       "1          2           3                 2        0  \n",
       "2          1           3                 7        0  \n",
       "3          2           3                 0        0  \n",
       "4          2           1                 5        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      "age                           10000 non-null int64\n",
      "cost_of_ad                    10000 non-null float64\n",
      "device_type                   10000 non-null object\n",
      "gender                        9731 non-null object\n",
      "in_initial_launch_location    10000 non-null int64\n",
      "income                        10000 non-null int64\n",
      "n_drivers                     10000 non-null int64\n",
      "n_vehicles                    10000 non-null int64\n",
      "prior_ins_tenure              10000 non-null int64\n",
      "outcome                       10000 non-null int64\n",
      "dtypes: float64(1), int64(7), object(2)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Checking for missing entries: Some of values in Gender are missing.\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Preprocessing(data):\n",
    "    \n",
    "    #Using simple backfill and forward technique to fill missing values.\n",
    "    data.fillna(method='bfill',inplace=True)\n",
    "    data.fillna(method='ffill',inplace=True)\n",
    "    \n",
    "    #Feature Engineering\n",
    "    data['Multiple_Vehicle']=data.apply(lambda x: 1 if x.n_vehicles>1 else 0, axis=1)\n",
    "    \n",
    "    def Age_Bin(Age):\n",
    "        Val=-1\n",
    "        if Age <=20:\n",
    "            Val=1\n",
    "        if Age >20 and Age<=40:\n",
    "            Val=2\n",
    "        else:\n",
    "            Val=3\n",
    "        return Val\n",
    "    data['Age_Bin']=data.apply(lambda x: Age_Bin(x.age), axis=1)\n",
    "    \n",
    "    \n",
    "    def Ads_Bin(Cost):\n",
    "        if Cost <0.004:\n",
    "            Val=1\n",
    "        if Cost >0.004 and Cost <0.005:\n",
    "            Val=2\n",
    "        if Cost >0.005 and Cost <0.006:\n",
    "            Val=3\n",
    "        if Cost >0.006:\n",
    "            Val=4\n",
    "        return Val\n",
    "    data['Cheap_Ads']=data.apply(lambda x: Ads_Bin(x.cost_of_ad), axis=1)\n",
    "    \n",
    "    \n",
    "    def Income_Bin(Income):\n",
    "        Val=0\n",
    "        if Income<=25000:\n",
    "            Val=1\n",
    "        if Income>25000 and Income<=50000:\n",
    "            Val=2\n",
    "        if Income>50000 and Income<=75000:\n",
    "            Val=3\n",
    "        if Income>75000:\n",
    "            Val=4\n",
    "        return Val\n",
    "    data['Income_Bin']=data.apply(lambda x: Income_Bin(x.income), axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def Tenure_Bin(Income):\n",
    "        if Income<6:\n",
    "            Val=0\n",
    "        else:\n",
    "            Val=1\n",
    "        return Val\n",
    "    data['Tenure_Bin']=data.apply(lambda x: Tenure_Bin(x.prior_ins_tenure), axis=1)\n",
    "    \n",
    "    \n",
    "    def Mobile_Operations(Device):\n",
    "        if Device=='iPhone' or Device=='Android':\n",
    "            Val=1\n",
    "        else:\n",
    "            Val=0\n",
    "        return Val\n",
    "    data['Mobile_Operations']=data.apply(lambda x: Mobile_Operations(x.device_type), axis=1)\n",
    "    \n",
    "    \n",
    "    def Tenure_And_Income(income,tenure):\n",
    "        Val=tenure/income\n",
    "        return Val\n",
    "    data['Tenure_And_Income']=data.apply(lambda x: Tenure_And_Income(x.income,x.prior_ins_tenure), axis=1)\n",
    "    \n",
    "    \n",
    "    def Number_Of_Vehicle_Per_Driver(Driver,Vehicle):\n",
    "        Val=Vehicle/Driver\n",
    "        return Val\n",
    "    data['Number_Of_Vehicle_Per_Driver']=data.apply(lambda x: Number_Of_Vehicle_Per_Driver(x.n_drivers,x.n_vehicles), axis=1)\n",
    "    \n",
    "    \n",
    "    #Label Encoding: Handling Categorical Variable\n",
    "    from sklearn.preprocessing  import LabelEncoder\n",
    "    def MultilabelEncoder(ColumnList, DataFrame):\n",
    "        for i in ColumnList:\n",
    "            labelencoder_x=LabelEncoder()\n",
    "            DataFrame[i]=labelencoder_x.fit_transform(DataFrame[i].astype(str))\n",
    "\n",
    "    ColumnList=['device_type','gender']\n",
    "    MultilabelEncoder(ColumnList,data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cost_of_ad</th>\n",
       "      <th>device_type</th>\n",
       "      <th>gender</th>\n",
       "      <th>in_initial_launch_location</th>\n",
       "      <th>income</th>\n",
       "      <th>n_drivers</th>\n",
       "      <th>n_vehicles</th>\n",
       "      <th>prior_ins_tenure</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Multiple_Vehicle</th>\n",
       "      <th>Age_Bin</th>\n",
       "      <th>Cheap_Ads</th>\n",
       "      <th>Income_Bin</th>\n",
       "      <th>Tenure_Bin</th>\n",
       "      <th>Mobile_Operations</th>\n",
       "      <th>Tenure_And_Income</th>\n",
       "      <th>Number_Of_Vehicle_Per_Driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62717</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64328</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83439</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30110</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76565</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  cost_of_ad  device_type  gender  in_initial_launch_location  income  \\\n",
       "0   56    0.005737            2       1                           0   62717   \n",
       "1   50    0.004733            1       0                           0   64328   \n",
       "2   54    0.004129            3       1                           0   83439   \n",
       "3   16    0.005117            0       0                           0   30110   \n",
       "4   37    0.003635            1       1                           0   76565   \n",
       "\n",
       "   n_drivers  n_vehicles  prior_ins_tenure  outcome  Multiple_Vehicle  \\\n",
       "0          2           1                 4        0                 0   \n",
       "1          2           3                 2        0                 1   \n",
       "2          1           3                 7        0                 1   \n",
       "3          2           3                 0        0                 1   \n",
       "4          2           1                 5        0                 0   \n",
       "\n",
       "   Age_Bin  Cheap_Ads  Income_Bin  Tenure_Bin  Mobile_Operations  \\\n",
       "0        3          3           3           0                  1   \n",
       "1        3          2           3           0                  0   \n",
       "2        3          2           4           1                  0   \n",
       "3        3          3           2           0                  1   \n",
       "4        2          1           4           0                  0   \n",
       "\n",
       "   Tenure_And_Income  Number_Of_Vehicle_Per_Driver  \n",
       "0           0.000064                           0.5  \n",
       "1           0.000031                           1.5  \n",
       "2           0.000084                           3.0  \n",
       "3           0.000000                           1.5  \n",
       "4           0.000065                           0.5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=Data_Preprocessing(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Scaling(data):\n",
    "    #Storing all column names in variable\n",
    "    Columns=data.columns\n",
    "    #Scaling Data \n",
    "    scaler = StandardScaler()\n",
    "    #print(scaler.fit(data))\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    data_Scaled = pd.DataFrame(scaled_data)\n",
    "    data_Scaled.columns =Columns\n",
    "    return data_Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Multiple_Vehicle               -0.200100\n",
       "n_vehicles                     -0.193192\n",
       "Number_Of_Vehicle_Per_Driver   -0.191886\n",
       "device_type                    -0.166496\n",
       "cost_of_ad                     -0.077210\n",
       "Cheap_Ads                      -0.069282\n",
       "Tenure_And_Income              -0.038633\n",
       "Tenure_Bin                     -0.038285\n",
       "prior_ins_tenure               -0.029934\n",
       "age                            -0.011907\n",
       "income                          0.006375\n",
       "Income_Bin                      0.017566\n",
       "Age_Bin                         0.019438\n",
       "Mobile_Operations               0.052894\n",
       "n_drivers                       0.100105\n",
       "in_initial_launch_location      0.116577\n",
       "gender                          0.137204\n",
       "outcome                         1.000000\n",
       "Name: outcome, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Correlation=data.corr()\n",
    "Correlation[\"outcome\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\Python\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int32, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "X=data[['Multiple_Vehicle','Mobile_Operations','gender','device_type','Cheap_Ads','Tenure_Bin','age','Income_Bin','n_drivers','in_initial_launch_location']]\n",
    "Y=data['outcome']\n",
    "\n",
    "Predictor_Columns=X.columns\n",
    "#Scaling the data\n",
    "X_Scaled=Data_Scaling(X)\n",
    "\n",
    "#Dataset split is 80% Training and 20% Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X_Scaled, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [7197 7197]\n"
     ]
    }
   ],
   "source": [
    "#Handling Data Imbalance:Synthetic Minority Oversampling Technique\n",
    "sm=SMOTE()\n",
    "X_Resampled, Y_Resampled=sm.fit_sample(X_Train,Y_Train)\n",
    "unique, counts=np.unique(Y_Resampled,return_counts= True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Random Forest Classifier: 0.81\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Random_Forest=RandomForestClassifier(max_depth=12, random_state=42,n_estimators=100)\n",
    "model1=Random_Forest.fit(X_Resampled,Y_Resampled)\n",
    "RF_Pred=Random_Forest.predict_proba(X_Test)[:,1]\n",
    "\n",
    "#Model Evaluation: AUC SCORE\n",
    "auc = roc_auc_score(Y_Test,RF_Pred)\n",
    "print('AUC Score for Random Forest Classifier: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Extra Tree Classifier: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Extra Tree Classfier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "Extra_Tree=ExtraTreesClassifier(max_depth=8, random_state=42)\n",
    "model2=Extra_Tree.fit(X_Resampled, Y_Resampled)\n",
    "Y_Pred_ET=Extra_Tree.predict_proba(X_Test)[:,1]\n",
    "\n",
    "#Model Evaluation: AUC SCORE\n",
    "auc = roc_auc_score(Y_Test,Y_Pred_ET)\n",
    "print('AUC Score for Extra Tree Classifier: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [50, 100, 125, 150, 175, 200, 225, 250, 275, 300], 'max_features': [2, 4, 6, 8, 10], 'max_depth': [2, 4, 8, 12, 16, 20, 32, 40, 64, 128], 'min_samples_split': [2, 5, 8, 10], 'min_samples_leaf': [1, 2, 4, 6, 8], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [50,100,125,150,175,200,225,250,275,300]\n",
    "# Number of features to consider at every split\n",
    "max_features = [2,4,6,8,10]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2,4,8,12,16,20,32,40,64,128]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5,8,10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [50, 100, 125, 150, 175, 200, 225, 250, 275, 300], 'max_features': [2, 4, 6, 8, 10], 'max_depth': [2, 4, 8, 12, 16, 20, 32, 40, 64, 128], 'min_samples_split': [2, 5, 8, 10], 'min_samples_leaf': [1, 2, 4, 6, 8], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ET = ExtraTreesClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "ET_random = RandomizedSearchCV(estimator = ET, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "ET_random.fit(X_Resampled,Y_Resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150,\n",
       " 'min_samples_split': 8,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 2,\n",
       " 'max_depth': 32,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best parameters\n",
    "ET_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Hyper Parameter Tuned Extra Tree Classifier is: 0.83\n"
     ]
    }
   ],
   "source": [
    "#Extra Tree Classfier: Hyper Parameter Tuned\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "Extra_Tree_Tuned=ExtraTreesClassifier(max_depth=12, random_state=42, n_estimators=150,min_samples_split=2,\n",
    "                               min_samples_leaf=4,max_features=2,bootstrap=False)\n",
    "model2=Extra_Tree_Tuned.fit(X_Resampled, Y_Resampled)\n",
    "Y_Pred_ET_Tuned=Extra_Tree_Tuned.predict_proba(X_Test)[:,1]\n",
    "\n",
    "#Model Evaluation: AUC SCORE\n",
    "auc = roc_auc_score(Y_Test,Y_Pred_ET_Tuned)\n",
    "print('AUC Score for Hyper Parameter Tuned Extra Tree Classifier is: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Gradient Boosting Classifier is: 0.83\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "Grad_Boost=GradientBoostingClassifier(max_depth=3,random_state=42)\n",
    "model3=Grad_Boost.fit(X_Resampled, Y_Resampled)\n",
    "Y_Pred_Grad=Grad_Boost.predict_proba(X_Test)[:,1]\n",
    "\n",
    "#Model Evaluation: AUC SCORE\n",
    "auc = roc_auc_score(Y_Test,Y_Pred_Grad)\n",
    "print('AUC Score for Gradient Boosting Classifier is: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Logistic Regression Classifier is: 0.80\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Logistic_Regression=LogisticRegression(random_state=42,solver='lbfgs')\n",
    "model4=Logistic_Regression.fit(X_Resampled,Y_Resampled)\n",
    "Y_Pred_Log=Logistic_Regression.predict_proba(X_Test)[:,1]\n",
    "\n",
    "#Model Evaluation: AUC SCORE\n",
    "auc = roc_auc_score(Y_Test,Y_Pred_Log)\n",
    "print('AUC Score for Logistic Regression Classifier is: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Voting Classifier Classifier: 0.83\n"
     ]
    }
   ],
   "source": [
    "#Voting Classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "Voting_Classifier=VotingClassifier(estimators=[('Extra_Tree',Extra_Tree),('Grad_Boost',Grad_Boost),('Logistic_Regression',Logistic_Regression)],\n",
    "                                  voting='soft')\n",
    "\n",
    "for clf in (Extra_Tree,Grad_Boost,Logistic_Regression,Voting_Classifier):\n",
    "    clf.fit(X_Resampled,Y_Resampled)\n",
    "    Voting_Prediction=clf.predict_proba(X_Test)[:,1]\n",
    "\n",
    "#Model Evaluation: AUC SCORE\n",
    "auc = roc_auc_score(Y_Test,Voting_Prediction)\n",
    "print('AUC Score for Voting Classifier Classifier: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Support Vector Classifier: 0.80\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Classifier\n",
    "from sklearn.svm import SVC\n",
    "SVM_clf=SVC(kernel='poly', probability=True)\n",
    "SVM_clf.fit(X_Resampled,Y_Resampled)\n",
    "Y_Pred_SVM=SVM_clf.predict_proba(X_Test)[:,1]\n",
    "\n",
    "#Model Evaluation: AUC SCORE\n",
    "auc = roc_auc_score(Y_Test,Y_Pred_SVM)\n",
    "print('AUC Score for Support Vector Classifier: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Random Forest Classifier: 0.78\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Decision_Tree = DecisionTreeClassifier(random_state = 42,max_depth=4,\n",
    "                                    criterion = 'gini',  splitter='best', min_samples_leaf=2, min_samples_split=4)\n",
    "Decision_Tree.fit(X_Resampled,Y_Resampled)\n",
    "Y_Pred_DT=Decision_Tree.predict_proba(X_Test)[:,1]\n",
    "\n",
    "#Model Evaluation: AUC SCORE\n",
    "auc = roc_auc_score(Y_Test,Y_Pred_DT)\n",
    "print('AUC Score for Random Forest Classifier: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Boosted Extra Tree Classifier: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "bdt = AdaBoostClassifier(ExtraTreesClassifier(max_depth=8, random_state=42, n_estimators=150,min_samples_split=2,\n",
    "                               min_samples_leaf=4,max_features=2,bootstrap=False),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=100)\n",
    "bdt.fit(X_Resampled,Y_Resampled)\n",
    "\n",
    "#Model Evaluation: AUC SCORE\n",
    "Pred=bdt.predict_proba(X_Test)[:,1]\n",
    "auc = roc_auc_score(Y_Test,Pred)\n",
    "print('AUC Score for Boosted Extra Tree Classifier: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\keras\\callbacks.py:511: RuntimeWarning: EarlyStopping mode <built-in function max> is unknown, fallback to auto mode.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "14394/14394 [==============================] - 1s 35us/step - loss: 0.6513 - auc: 0.6457\n",
      "Epoch 2/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.5153 - auc: 0.7514\n",
      "Epoch 3/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4879 - auc: 0.7823\n",
      "Epoch 4/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4747 - auc: 0.8009\n",
      "Epoch 5/150\n",
      "14394/14394 [==============================] - ETA: 0s - loss: 0.4620 - auc: 0.813 - 0s 12us/step - loss: 0.4625 - auc: 0.8140\n",
      "Epoch 6/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4533 - auc: 0.8237\n",
      "Epoch 7/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4471 - auc: 0.8313\n",
      "Epoch 8/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4425 - auc: 0.8371\n",
      "Epoch 9/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4397 - auc: 0.8417\n",
      "Epoch 10/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4373 - auc: 0.8455: 0s - loss: 0.4317 - auc: 0.84 - ETA: 0s - loss: 0.4368 - auc: 0.845\n",
      "Epoch 11/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4357 - auc: 0.8486\n",
      "Epoch 12/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4341 - auc: 0.8513\n",
      "Epoch 13/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4328 - auc: 0.8534\n",
      "Epoch 14/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4320 - auc: 0.8554\n",
      "Epoch 15/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4306 - auc: 0.8572\n",
      "Epoch 16/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4296 - auc: 0.8587\n",
      "Epoch 17/150\n",
      "14394/14394 [==============================] - ETA: 0s - loss: 0.4245 - auc: 0.8600- ETA: 0s - loss: 0.4339 - auc: 0.8 - 0s 13us/step - loss: 0.4285 - auc: 0.8601\n",
      "Epoch 18/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4283 - auc: 0.8614\n",
      "Epoch 19/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4269 - auc: 0.8624\n",
      "Epoch 20/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4264 - auc: 0.8634: 0s - loss: 0.4260 - auc: 0.863\n",
      "Epoch 21/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4255 - auc: 0.8644\n",
      "Epoch 22/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4246 - auc: 0.8652\n",
      "Epoch 23/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4246 - auc: 0.8661\n",
      "Epoch 24/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4233 - auc: 0.8668\n",
      "Epoch 25/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4228 - auc: 0.8676\n",
      "Epoch 26/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4226 - auc: 0.8682\n",
      "Epoch 27/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4219 - auc: 0.8688: 0s - loss: 0.4244 - auc: 0.86\n",
      "Epoch 28/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4209 - auc: 0.8695\n",
      "Epoch 29/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4205 - auc: 0.8700\n",
      "Epoch 30/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4205 - auc: 0.8705\n",
      "Epoch 31/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4193 - auc: 0.8710\n",
      "Epoch 32/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4190 - auc: 0.8715\n",
      "Epoch 33/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4190 - auc: 0.8720\n",
      "Epoch 34/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4179 - auc: 0.8724: 0s - loss: 0.4120 - auc: 0.87\n",
      "Epoch 35/150\n",
      "14394/14394 [==============================] - 0s 14us/step - loss: 0.4178 - auc: 0.8728\n",
      "Epoch 36/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4175 - auc: 0.8732\n",
      "Epoch 37/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4170 - auc: 0.8736\n",
      "Epoch 38/150\n",
      "14394/14394 [==============================] - 0s 16us/step - loss: 0.4161 - auc: 0.8740\n",
      "Epoch 39/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4155 - auc: 0.8744\n",
      "Epoch 40/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4153 - auc: 0.8747\n",
      "Epoch 41/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4148 - auc: 0.8750\n",
      "Epoch 42/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4141 - auc: 0.8754\n",
      "Epoch 43/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4136 - auc: 0.8757\n",
      "Epoch 44/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4138 - auc: 0.8760: 0s - loss: 0.4097 - auc: 0.87\n",
      "Epoch 45/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4126 - auc: 0.8763\n",
      "Epoch 46/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4125 - auc: 0.8766\n",
      "Epoch 47/150\n",
      "14394/14394 [==============================] - 0s 13us/step - loss: 0.4116 - auc: 0.8769\n",
      "Epoch 48/150\n",
      "14394/14394 [==============================] - 0s 14us/step - loss: 0.4123 - auc: 0.8771\n",
      "Epoch 49/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4111 - auc: 0.8774\n",
      "Epoch 50/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4111 - auc: 0.8777\n",
      "Epoch 51/150\n",
      "14394/14394 [==============================] - 0s 12us/step - loss: 0.4099 - auc: 0.8779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1af2ea03518>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neural Network\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "#Creating own evaluation parameter: AUC\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "callback = [EarlyStopping(monitor='auc', patience=50, mode=max),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='auc', save_best_only=True)]\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "NN_classifier = Sequential()\n",
    "# Adding the input layer and the first hidden layer\n",
    "NN_classifier.add(Dense(units =16 , kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
    "# Adding the second hidden layer\n",
    "NN_classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "NN_classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "# Compiling the ANN\n",
    "NN_classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics =[auc])\n",
    "# Fitting the ANN to the Training set\n",
    "NN_classifier.fit(X_Resampled,Y_Resampled, batch_size = 100, epochs = 150, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Random Forest Classifier: 0.81\n"
     ]
    }
   ],
   "source": [
    "ANN_predictions = NN_classifier.predict(X_Test)\n",
    "ANN_predictions=np.ravel(ANN_predictions)\n",
    "ANN_predictions\n",
    "\n",
    "#Model Evaluation: AUC SCORE\n",
    "auc = roc_auc_score(Y_Test,ANN_predictions)\n",
    "print('AUC Score for Random Forest Classifier: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Combined Ensemble Classifier: 0.826875\n"
     ]
    }
   ],
   "source": [
    "#Ensemble of all Models: Combining probabilities and Normalizing it\n",
    "Total=max(Y_Pred_ET_Tuned)+max(Y_Pred_Grad)+max(Y_Pred_Log)+max(ANN_predictions+max(Y_Pred_DT))\n",
    "Final_Prob=(Y_Pred_ET_Tuned+Y_Pred_Grad+Y_Pred_Log+ANN_predictions+Y_Pred_DT)/Total\n",
    "\n",
    "#Model Evaluation: AUC SCORE\n",
    "auc = roc_auc_score(Y_Test,Final_Prob)\n",
    "print('AUC Score for Combined Ensemble Classifier: %f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating complete funciton for data preprocessing, feature engineering and data scaling\n",
    "#Predicting the individual probabilities, creating ensemble and giving final output by attaching\n",
    "#Additional Calumn.\n",
    "\n",
    "def Final_Output(data):\n",
    "    Output=data.copy()\n",
    "    data=Data_Preprocessing(data)\n",
    "    data=Data_Scaling(data)\n",
    "    #data=data[['Multiple_Vehicle','Mobile_Operations','gender','device_type','Cheap_Ads','Tenure_Bin','age','Income_Bin','n_drivers','in_initial_launch_location']]\n",
    "    data=data[Predictor_Columns]\n",
    "    Y_Pred_ET_Tuned=Extra_Tree_Tuned.predict_proba(data)[:,1]\n",
    "    Y_Pred_Grad=Grad_Boost.predict_proba(data)[:,1]\n",
    "    Y_Pred_Log=Logistic_Regression.predict_proba(data)[:,1]\n",
    "    Y_Pred_DT=Decision_Tree.predict_proba(data)[:,1]\n",
    "    ANN_predictions = NN_classifier.predict(data)\n",
    "    ANN_predictions=np.ravel(ANN_predictions)\n",
    "    \n",
    "    Total=max(Y_Pred_ET_Tuned)+max(Y_Pred_Grad)+max(Y_Pred_Log)+max(ANN_predictions+max(Y_Pred_DT))\n",
    "    Final_Prob=(Y_Pred_ET_Tuned+Y_Pred_Grad+Y_Pred_Log+ANN_predictions+Y_Pred_DT)/Total\n",
    "    \n",
    "    Output['Outcome']=Final_Prob\n",
    "    return Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\Python\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int32, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cost_of_ad</th>\n",
       "      <th>device_type</th>\n",
       "      <th>gender</th>\n",
       "      <th>in_initial_launch_location</th>\n",
       "      <th>income</th>\n",
       "      <th>n_drivers</th>\n",
       "      <th>n_vehicles</th>\n",
       "      <th>prior_ins_tenure</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>Android</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>40376</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.391433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>desktop</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>84511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.716239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>laptop</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>79322</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.450985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>Android</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>63295</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.276288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>other</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>36170</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.270376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  cost_of_ad device_type gender  in_initial_launch_location  income  \\\n",
       "0   34    0.005134     Android      F                           1   40376   \n",
       "1   53    0.005223     desktop      F                           1   84511   \n",
       "2   46    0.004939      laptop      F                           0   79322   \n",
       "3   36    0.004924     Android      F                           0   63295   \n",
       "4   28    0.005146       other      F                           1   36170   \n",
       "\n",
       "   n_drivers  n_vehicles  prior_ins_tenure   Outcome  \n",
       "0          1           3                 7  0.391433  \n",
       "1          1           1                11  0.716239  \n",
       "2          1           1                 4  0.450985  \n",
       "3          1           2                 0  0.276288  \n",
       "4          1           3                 3  0.270376  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the dataset and passing it to above function to generate final output.\n",
    "test=pd.read_csv('test.csv')\n",
    "result=Final_Output(test)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Blue_Owl_Machine_Learning_Assignment.ipynb to html\n",
      "[NbConvertApp] Writing 362129 bytes to Blue_Owl_Machine_Learning_Assignment.html\n"
     ]
    }
   ],
   "source": [
    "#Converting notebook to HTML\n",
    "!jupyter nbconvert --to html Blue_Owl_Machine_Learning_Assignment.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code By Sudesh V Khillare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
